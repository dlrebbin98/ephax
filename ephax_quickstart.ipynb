{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc221e3b",
   "metadata": {},
   "source": [
    "# ephax Quickstart Tutorial\n",
    "\n",
    "Welcome! This notebook walks through a minimal workflow for the analyzer-first electrophysiology toolkit. You'll learn how to prepare a dataset, choose reference electrodes, and run a few of the provided analyzers on synthetic data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceaf1b8",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- Python 3.9+ with Jupyter installed (`pip install jupyterlab`)\n",
    "- The `ephax` package available in your environment (`pip install -e .` from the repository root)\n",
    "- MEA spike recordings in `.h5` or `.npz` form — we will start with a synthetic dataset you can run anywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa23b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "from ephax import RestingActivityDataset, PrepConfig, Recording\n",
    "from ephax.analyzers import IFRAnalyzer\n",
    "from ephax.analyzers.ifr import IFRConfig\n",
    "from ephax.analyzers.firing_distance import FiringDistanceAnalyzer\n",
    "from ephax.analyzers.cofiring_temporal import CofiringTemporalAnalyzer, CofiringTemporalConfig\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2f02d9",
   "metadata": {},
   "source": [
    "## Building a Synthetic Dataset\n",
    "\n",
    "If you do not have access to raw recordings yet, you can still explore the API with generated spike trains. The helper below creates a grid of electrodes, draws Poisson spike trains, and adds brief synchronous bursts across a few electrodes so that the downstream analyzers have interesting structure to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d860abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Tuple\n",
    "\n",
    "def simulate_recording(\n",
    "    seed: int,\n",
    "    duration_s: float = 60.0,\n",
    "    grid_side: int = 4,\n",
    "    base_rate_range: Tuple[float, float] = (5.0, 20.0),\n",
    ") -> Recording:\n",
    "    \"\"\"Create a Recording with synthetic spikes and square-grid layout.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n_electrodes = grid_side ** 2\n",
    "    channels = np.arange(n_electrodes, dtype=np.int32)\n",
    "    electrodes = np.arange(100, 100 + n_electrodes, dtype=np.int32)\n",
    "    pitch_um = 60.0\n",
    "    layout = {\n",
    "        \"channel\": channels,\n",
    "        \"electrode\": electrodes,\n",
    "        \"x\": ((channels % grid_side) * pitch_um).astype(np.float32),\n",
    "        \"y\": ((channels // grid_side) * pitch_um).astype(np.float32),\n",
    "    }\n",
    "\n",
    "    base_rates = rng.uniform(base_rate_range[0], base_rate_range[1], size=n_electrodes)\n",
    "    burst_times = rng.uniform(5.0, duration_s - 5.0, size=12)\n",
    "\n",
    "    all_times = []\n",
    "    all_channels = []\n",
    "    all_electrodes = []\n",
    "    all_amplitudes = []\n",
    "\n",
    "    for idx in range(n_electrodes):\n",
    "        baseline_count = rng.poisson(base_rates[idx] * duration_s)\n",
    "        baseline = rng.uniform(0.0, duration_s, size=baseline_count)\n",
    "        if idx < grid_side:\n",
    "            correlated = burst_times + rng.normal(scale=0.004, size=burst_times.shape)\n",
    "            correlated = np.clip(correlated, 0.0, duration_s)\n",
    "            spikes_t = np.concatenate([baseline, correlated])\n",
    "        else:\n",
    "            spikes_t = baseline\n",
    "        spikes_t = np.sort(spikes_t)\n",
    "        if spikes_t.size == 0:\n",
    "            continue\n",
    "        all_times.append(spikes_t.astype(np.float32))\n",
    "        all_channels.append(np.full(spikes_t.size, channels[idx], dtype=np.int32))\n",
    "        all_electrodes.append(np.full(spikes_t.size, electrodes[idx], dtype=np.int32))\n",
    "        all_amplitudes.append(rng.normal(loc=45.0, scale=5.0, size=spikes_t.size).astype(np.float32))\n",
    "\n",
    "    if not all_times:\n",
    "        raise RuntimeError(\"Synthetic recording is empty; adjust simulation parameters.\")\n",
    "\n",
    "    spikes = {\n",
    "        \"time\": np.concatenate(all_times),\n",
    "        \"channel\": np.concatenate(all_channels),\n",
    "        \"electrode\": np.concatenate(all_electrodes),\n",
    "        \"amplitude\": np.concatenate(all_amplitudes),\n",
    "    }\n",
    "\n",
    "    return Recording(\n",
    "        spikes=spikes,\n",
    "        layout=layout,\n",
    "        start_time=0.0,\n",
    "        end_time=float(duration_s),\n",
    "        sf=10_000.0,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4a7a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recordings = [simulate_recording(0), simulate_recording(42)]\n",
    "ds = RestingActivityDataset(recordings=recordings, sf=10_000.0)\n",
    "\n",
    "print(f\"Dataset contains {len(ds.recordings)} recordings\")\n",
    "for idx, rec in enumerate(ds.recordings):\n",
    "    spike_count = len(rec.spikes[\"time\"])\n",
    "    electrode_count = np.unique(rec.spikes[\"electrode\"]).size\n",
    "    duration = rec.end_time - rec.start_time\n",
    "    print(f\"  Recording {idx}: {spike_count} spikes across {electrode_count} electrodes in {duration:.1f} s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd5a6e7",
   "metadata": {},
   "source": [
    "## Selecting Reference Electrodes with `PrepConfig`\n",
    "\n",
    "Analyzers expect a list of reference electrodes per recording. `PrepConfig` lets you request them by activity threshold, by rank, or by providing an explicit list. Here we pick the top few most active electrodes within each recording window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84cb535",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prep_cfg = PrepConfig(mode=\"top\", top_start=0, top_stop=6, verbose=False)\n",
    "refs_per_recording = ds.select_ref_electrodes(prep_cfg)\n",
    "for idx, refs in enumerate(refs_per_recording):\n",
    "    preview = \", \".join(map(str, refs[:5])) + (\"…\" if refs.size > 5 else \"\")\n",
    "    print(f\"Recording {idx}: selected {refs.size} reference electrodes ({preview})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c920a972",
   "metadata": {},
   "source": [
    "## Instantaneous Firing Rate (IFR) Analysis\n",
    "\n",
    "`IFRAnalyzer` pools spikes across recordings, computes instantaneous firing rate samples, optionally fits a Gaussian mixture model, and can render per-recording heatmaps. We reuse our `PrepConfig` so the analyzer focuses on the same reference electrodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa464a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ifr_cfg = IFRConfig(log_scale=True, hist_bins=60, overlay_gmm=True, time_grid_hz=200.0, max_time_points=2_000)\n",
    "ifr_analyzer = IFRAnalyzer.from_dataset(ds, config=ifr_cfg, selection_prep_config=prep_cfg)\n",
    "peaks = ifr_analyzer.peaks()\n",
    "print(f\"Collected {peaks.values.size} IFR samples\")\n",
    "if peaks.peaks_hz.size:\n",
    "    print(\"GMM peak locations (Hz):\", np.round(peaks.peaks_hz, 2))\n",
    "else:\n",
    "    print(\"No peaks detected — consider widening the selection window.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e87d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = ifr_analyzer.plot_histogram()\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dba255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ts_figs = ifr_analyzer.plot_timeseries()\n",
    "for fig, axes in ts_figs:\n",
    "    display(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73a685b",
   "metadata": {},
   "source": [
    "## Distance-Dependent Firing Statistics\n",
    "\n",
    "`FiringDistanceAnalyzer` aggregates firing or co-firing metrics as a function of inter-electrode distance. Even with synthetic data, you can inspect whether firing rates decay with distance, and overlay the theoretical synergy curve derived from the detected IFR peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9af0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fd_analyzer = FiringDistanceAnalyzer(ds, selection_prep_config=prep_cfg)\n",
    "rate_vs_distance = fd_analyzer.avg_rate_vs_distance()\n",
    "fig, _ = fd_analyzer.plot_rate_with_synergy(rate_vs_distance, show_exponential_fit=False)\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80cadf",
   "metadata": {},
   "source": [
    "## Temporal Co-firing Heatmap\n",
    "\n",
    "`CofiringTemporalAnalyzer` summarizes how co-firing probability changes with inter-electrode distance and temporal delay. The visualization below averages across reference electrodes and recordings using the same selection we defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf8245",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cft_cfg = CofiringTemporalConfig(start_ms=-20, stop_ms=120, step_ms=20, normalize=False)\n",
    "cft_analyzer = CofiringTemporalAnalyzer(ds, cft_cfg, selection_prep_config=prep_cfg)\n",
    "fig, ax = cft_analyzer.plot_avg_cofiring_heatmap()\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e3c36e",
   "metadata": {},
   "source": [
    "### Bundled Example Recordings\n",
    "\n",
    "The repository ships with short `.raw.h5` snippets under `ephax/data`. Load them by pointing `file_info` at that folder:\n",
    "\n",
    "```python\n",
    "from pathlib import Path\n",
    "from ephax import RestingActivityDataset\n",
    "\n",
    "repo_root = Path.cwd()  # run the notebook from the repository root\n",
    "file_info = [\n",
    "    (\"ephax/data\", \"well_0.raw.h5\", 0, 600, 0),\n",
    "    (\"ephax/data\", \"well_1.raw.h5\", 0, 600, 1),\n",
    "    (\"ephax/data\", \"well_2_3.raw.h5\", 0, 600, 2),\n",
    "    (\"ephax/data\", \"well_2_3.raw.h5\", 0, 600, 3),\n",
    "    (\"ephax/data\", \"well_4.raw.h5\", 0, 600, 4),\n",
    "    (\"ephax/data\", \"well_5.raw.h5\", 0, 600, 5),\n",
    "]\n",
    "\n",
    "def resolve(entry):\n",
    "    folder, filename, start, end, well = entry\n",
    "    folder_path = repo_root / folder\n",
    "    return (folder_path.as_posix(), filename, start, end, well)\n",
    "\n",
    "resolved_info = [resolve(item) for item in file_info]\n",
    "ds = RestingActivityDataset.from_file_info(resolved_info, source=\"h5\", min_amp=0)\n",
    "```\n",
    "\n",
    "If you launch Jupyter from elsewhere, adjust `repo_root` accordingly or provide absolute paths in `file_info`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65431f26",
   "metadata": {},
   "source": [
    "## Working with Your Own Recordings\n",
    "\n",
    "Replace the synthetic dataset with real recordings by preparing a `file_info` list and calling `RestingActivityDataset.from_file_info`:\n",
    "\n",
    "```python\n",
    "file_info = [\n",
    "    (\"2407\", \"control_0.raw.h5\", 0, 600, 0),  # (folder/div, filename, start_s, end_s, well)\n",
    "    (\"2407\", \"control_1.raw.h5\", 0, 600, 1),\n",
    "]\n",
    "ds = RestingActivityDataset.from_file_info(file_info, source=\"h5\", min_amp=0)\n",
    "```\n",
    "\n",
    "After loading, keep the rest of the notebook unchanged: reuse `PrepConfig`, instantiate analyzers, and iterate on configuration parameters as needed. Consult `README.md` for additional analyzers (stability, DCT, GIF generation) and advanced options such as permutation controls."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
